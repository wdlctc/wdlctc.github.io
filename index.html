<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Cheng Luo - Personal Page</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            line-height: 1.6;
        }
        nav {
            text-align: right;
        }
        nav a {
            margin-left: 15px;
            text-decoration: none;
            color: #0066cc;
        }
        img {
            display: block;
            width: 200px;
            border-radius: 50%;
            margin: 20px auto;
        }
        h1 {
            text-align: center;
        }
        .news {
            margin-top: 30px;
        }
        .news-item {
            margin-bottom: 10px;
        }
        .date {
            font-weight: bold;
            margin-right: 10px;
        }
        .social-icons {
            text-align: center;
            margin-top: 30px;
        }
        .social-icons img {
            width: 30px;
            margin: 0 10px;
            display: inline;
        }
    </style>
</head>
<body>
    <nav>
        <a href="#about">About</a>
        <a href="research.html">Research</a>
        <a href="blogs.html">Blog</a>
    </nav>

    <img src="profile-picture.jpg" alt="Cheng Luo">
    <h1>Cheng Luo</h1>

    <p>I am a independent researcher focusing on LLM optimization.  Before that, I was an research at <a href="https://www.microsoft.com/en-us/research/">Microsoft Research</a>. I am also collaborating with <a href="http://tensorlab.cms.caltech.edu/users/anima/"> Anima Anandkumar.</a> at Caltech, <a href="https://www.andrew.cmu.edu/user/beidic/">Beidi Chen</a> at CMU. I am currently a postdoctoral researcher at caltech.</p>

    <p>I am interested in bridging hardware constraints with the principles of learning in neural networks. I focus on developing hardware-efficient learning algorithms that are principled and scalable for large-scale training, such as training large language models (LLMs). Check out my <a href="https://scholar.google.com/citations?user=jmCDQGoAAAAJ&hl=en">research</a> for more details.</p>

    <p>Additionally, I am a passionate community builder, which I founded the <a href=https://efficient-reasoning.github.io/"> Efficient Reasoning </a> workshops. </p>

    <!-- <p>Reach me at firstname at caltech dot edu</p> -->

    <div class="news">
        <h2>news</h2>
        <div class="news-item">
            <span class="date">Jul, 2024</span>
            <a href="https://github.com/wdlctc/headinfer">HeadInfer</a> is released and try it out ðŸ™Œ
        </div>
        <div class="news-item">
            <span class="date">Jul, 2024</span>
            <a href="https://github.com/wdlctc/mini-s">MsT</a> is released and try it out ðŸ™Œ
        </div>
        <div class="news-item">
            <span class="date">Mar, 2024</span>
            <a href="https://github.com/wdlctc/rtp">RTP</a> is released and try it out ðŸ™Œ
        </div>
    </div>

    <div class="social-icons">
        <a href="https://scholar.google.com/citations?user=jmCDQGoAAAAJ&hl=en"><img src="google-scholar-icon.png" alt="Google Scholar"></a>
        <a href="https://github.com/wdlctc"><img src="github-icon.png" alt="GitHub"></a>
    </div>
</body>
</html>